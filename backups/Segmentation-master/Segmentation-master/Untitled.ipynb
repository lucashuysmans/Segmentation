{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SebastianConvNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (conv6): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (linear1): Linear(in_features=8192, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ClassFiles.networks import SebastianConvNet\n",
    "NN = SebastianConvNet(1, 128, 128)\n",
    "NN.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained performance 0.01816600374877453 0.01816578023135662\n",
      "done epoch -8.000093460083008 16.019254684448242\n",
      "done epoch -195.02183532714844 -169.8485565185547\n",
      "done epoch -126.47249603271484 -99.04129028320312\n",
      "done epoch -161.04489135742188 -128.82681274414062\n",
      "done epoch -278.68670654296875 -246.34097290039062\n",
      "done epoch -222.69346618652344 -188.8977508544922\n",
      "done epoch -284.9851989746094 -258.94720458984375\n",
      "done epoch -188.89401245117188 -157.72146606445312\n",
      "done epoch -173.2315216064453 -143.59625244140625\n",
      "done epoch -300.61090087890625 -278.0100402832031\n"
     ]
    }
   ],
   "source": [
    "from algorithm1 import train\n",
    "NN = train(NN, 'local_testing_net', epochs = 10, batch_size = 50 , mu = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1111.72314453125 -300.61090087890625 -278.0100402832031\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ClassFiles.DataLoader import get_generated_dataloader\n",
    "from ClassFiles.networks import SebastianConvNet\n",
    "from algorithm2_old import reconstruct, minimum\n",
    "\n",
    "eval_groundtruth_loader = get_generated_dataloader('eval', 'clean', batch_size = 100, shuffle = False)\n",
    "eval_chanvese_loader = get_generated_dataloader('eval', 'chan-vese', batch_size = 100, shuffle = False)\n",
    "eval_noisy_loader = get_generated_dataloader('eval', 'dirty', batch_size = 100, shuffle = False)\n",
    "\n",
    "eval_groundtruth_batch = iter(eval_groundtruth_loader).next()[0].to(\"cuda\")\n",
    "eval_chanvese_batch = iter(eval_chanvese_loader).next()[0].to(\"cuda\")\n",
    "eval_noisy_batch = iter(eval_noisy_loader).next()[0].to(\"cuda\")\n",
    "\n",
    "NN.to(\"cuda\")\n",
    "\n",
    "#reconstructed_batch, quality, steps = minimum(eval_chanvese_batch, eval_noisy_batch, eval_groundtruth_batch, NN, 1, 0.001)\n",
    "#print(steps)\n",
    "\n",
    "reconstructed_batch, _ = reconstruct(eval_chanvese_batch, eval_noisy_batch, NN, 1, 0.004, 50) #c1 = torch.zeros([1], device = \"cuda\"), c2 = torch.ones([1], device = \"cuda\"))\n",
    "\n",
    "#reconstructed_batch, _ = reconstruct(eval_noisy_batch, eval_noisy_batch, NN, 0, 16000, 400) #c1 = torch.zeros([1], device = \"cuda\"), c2 = torch.ones([1], device = \"cuda\"))\n",
    "\n",
    "#reconstructed_batch, _ = shitty_reconstruct(eval_chanvese_batch, eval_noisy_batch, NN, 0.01, 50)\n",
    "\n",
    "print(NN(reconstructed_batch).mean().item(), NN(eval_groundtruth_batch).mean().item(), NN(eval_chanvese_batch).mean().item()) \n",
    "\n",
    "reconstructed_batch_numpy = reconstructed_batch.to(\"cpu\").numpy()\n",
    "reconstructed_batch_numpy_squeeze = reconstructed_batch_numpy.squeeze()\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(100):\n",
    "    im = Image.fromarray(255*reconstructed_batch_numpy_squeeze[i]).convert(\"L\")\n",
    "    im.save(fp =  \"eval/images/reconstructed/reconstructed_\"+str(i).zfill(2)+\".png\", format = 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
